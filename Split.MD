---
marp: true
theme: gaia
class: lead
backgroundColor: '#2ECC71'
color: '#FFFFFF'
style: |
  section {
    color: #FFFFFF;
    background-color: #2ECC71;
  }
  h1 {
    color: #FFFFFF;
  }
  h2 {
    color: #FFFFFF;
  }
  p {
    color: #FFFFFF;
  }
  .emoji {
    display: inline-block;
    vertical-align: middle;
  }
---

# DivisiÃ³n de Datos ğŸ“šğŸ”
Uno de los pasos fundamentales en el preprocesamiento de los datos antes de aplicar un algoritmo de aprendizaje automÃ¡tico es dividir los datos en dos conjuntos: el conjunto de entrenamiento y el conjunto de prueba. ğŸ‹ï¸â€â™‚ï¸ğŸ¯

---

# DivisiÃ³n de Datos ğŸ“šğŸ”
El conjunto de entrenamiento se usa para entrenar nuestro modelo, es decir, para ajustar los parÃ¡metros de nuestro algoritmo de aprendizaje automÃ¡tico. El conjunto de prueba se usa para evaluar el rendimiento de nuestro modelo en datos no vistos previamente. ğŸŒ

---

# Razones para la DivisiÃ³n ğŸ§
La principal razÃ³n para dividir los datos en estos dos conjuntos es evitar el sobreajuste. El sobreajuste ocurre cuando nuestro modelo se ajusta muy bien a los datos de entrenamiento, pero no se desempeÃ±a bien en los datos de prueba o en datos nuevos. ğŸ˜±

---

# Razones para la DivisiÃ³n ğŸ§
Al reservar un conjunto de datos para las pruebas, podemos verificar si nuestro modelo es capaz de generalizar bien a datos nuevos.

---

# Â¿CÃ³mo Dividir los Datos? ğŸ“
En general, se utiliza una proporciÃ³n de 70-30 o 80-20 para la divisiÃ³n de los datos. Es decir, el 70-80% de los datos se utilizan para el entrenamiento, y el 20-30% restante se utiliza para las pruebas. 

---

# Â¿CÃ³mo Dividir los Datos? ğŸ“
Es importante recordar que los datos deben ser divididos de manera aleatoria para evitar cualquier sesgo en el entrenamiento o en las pruebas. En algunos casos, tambiÃ©n puede ser Ãºtil utilizar una tÃ©cnica llamada validaciÃ³n cruzada.

---

# ValidaciÃ³n Cruzada â±
La validaciÃ³n cruzada es una tÃ©cnica que nos permite usar todos nuestros datos para el entrenamiento y para las pruebas. Dividimos nuestros datos en 'k' partes iguales, o 'folds'.

---

# ValidaciÃ³n Cruzada â±
Luego, entrenamos nuestro modelo 'k' veces, cada vez usando un 'fold' diferente como nuestro conjunto de prueba y los 'folds' restantes como nuestro conjunto de entrenamiento. 

---

# ValidaciÃ³n Cruzada â±
Finalmente, promediamos los resultados de estas 'k' pruebas para obtener una medida mÃ¡s robusta de la capacidad de nuestro modelo para generalizar a nuevos datos. La validaciÃ³n cruzada puede ser mÃ¡s costosa en tÃ©rminos de tiempo y recursos computacionales, pero a menudo proporciona una evaluaciÃ³n mÃ¡s precisa de nuestro modelo. ğŸ”„
