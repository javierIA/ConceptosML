---
marp: true
theme: gaia
style: |
  section {
    background-color: #ECF0F1;
    color: #2C3E50;
  }
  h1, h2, h3 {
    color: #16A085;
  }
---

# Funci贸n de P茅rdida (Loss Function) 

La **funci贸n de p茅rdida** mide la discrepancia entre la predicci贸n del modelo y el valor verdadero. Es una m茅trica de "lo mal" que le va a nuestro modelo.

![Loss Function](https://www.researchgate.net/publication/343355071/figure/tbl1/AS:939383976886273@1600978001211/Examples-of-commonly-used-loss-functions-in-machine-learning.pngo.medium.com/max/966/1*3MSgKdkVx0H_mW3X9rn4ZQ.png)

---

# Funci贸n de P茅rdida (Loss Function) 

Su principal objetivo es encontrar el conjunto de par谩metros del modelo que minimizan la funci贸n de p茅rdida.

- Ejemplos comunes incluyen: 
  - Error cuadr谩tico medio (para regresi贸n)
  - Cross entropy loss (para clasificaci贸n)

---

# Criterio de Optimizaci贸n (Optimization Criteria) 

El **criterio de optimizaci贸n** mide la efectividad general del modelo en todo el conjunto de datos. 

- Por lo general, se basa en la funci贸n de p茅rdida y busca minimizar el error en todas las instancias del conjunto de datos.

---

# Criterio de Optimizaci贸n (Optimization Criteria) 

Por ejemplo, una **funci贸n de coste** podr铆a ser el promedio del valor de la funci贸n de p茅rdida sobre todas las instancias. 

![Cost Function](https://decidesoluciones.es/wp-content/uploads/2020/11/Imagen1.png)

---

# Rutina de Optimizaci贸n (Optimization Routine) 锔

Es el proceso por el cual se va a manejar la informaci贸n para encontrar una soluci贸n al criterio de optimizaci贸n. 

- M茅todos comunes incluyen el **descenso del gradiente** y variantes del mismo.

---

# Rutina de Optimizaci贸n (Optimization Routine) 锔

La rutina de optimizaci贸n se encarga de actualizar los par谩metros del modelo con el fin de minimizar la funci贸n de coste.


---
# Resultado del Aprendizaje Autom谩tico 
-El resultado de aplicar el algoritmo de aprendizaje sobre un conjunto de datos es un modelo, este modelo nos permitir谩 realizar predicciones sobre los nuevos elementos no asociados a una informaci贸n de salida.

---
# Resultado del Aprendizaje Autom谩tico 
![bg : 90%](https://amr205.github.io/Introduccion-a-la-IA---Libro/pandocConversionMedia/d317b648075cb87b555b01e6036e613e5fe139c2.png)
---

---

# Overfitting y Underfitting 

Cuando entrenamos modelos de machine learning, es com煤n encontrar problemas de overfitting o underfitting. Ambos problemas se relacionan con c贸mo de bien nuestro modelo se ajusta a los datos de entrenamiento y c贸mo de bien generaliza a datos no vistos.

---

# Overfitting 

El **overfitting** ocurre cuando el modelo se ajusta demasiado bien a los datos de entrenamiento, hasta el punto de aprender el ruido presente en estos datos. Como resultado, el modelo tendr谩 problemas para generalizar a datos no vistos.

- Se帽al vs Ruido
  - Se帽al: Funci贸n o patr贸n "verdadero" que intentamos extraer de los datos.
  - Ruido: Errores de medici贸n, aleatoriedad en los datos, valores at铆picos (outliers).

---

![bg left: 100% ](images/image.png)

---
# Underfitting 

El **underfitting** es el problema contrario al overfitting. Se produce cuando nuestro modelo no es lo suficientemente complejo para captar la relaci贸n entre los datos de entrada X y los datos de salida Y.

- En este caso, el modelo tiene un mal rendimiento tanto en el conjunto de entrenamiento como en el conjunto de prueba.



---

# Detectando Overfitting y Underfitting 
- Detectar si un modelo tiene overfitting o underfitting comparando su desempe帽o en el set de entrenamiento y el set de prueba:

- Si el rendimiento en el set de entrenamiento es significativamente mejor que en el set de prueba, probablemente estemos ante un caso de overfitting.
- Si el rendimiento es bajo tanto en el set de entrenamiento como en el set de prueba, probablemente estemos ante un caso de underfitting.

---

# 驴C贸mo combatir el Overfitting? 

Aqu铆 hay algunas estrategias para prevenir el overfitting:

- Recolectar m谩s datos.
- Remover caracter铆sticas irrelevantes.
- Utilizar t茅cnicas de regularizaci贸n que hacen al modelo m谩s simple.
- Utilizar early stopping (aunque esta t茅cnica se usa con precauci贸n).
- Ajustar los par谩metros del modelo utilizando un set de validaci贸n.
